{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1iHAhY4LXxpWw_R4DriN2EijhaUBcjrlP",
      "authorship_tag": "ABX9TyPEC29ckJhMpggjPJM8y4qf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReevaKanakhara/EcoWatch-AI-Hacksagon/blob/main/EcoWatch_Dashboard_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q earthengine-api geemap"
      ],
      "metadata": {
        "id": "kZj8g2FADpUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "import geemap\n",
        "\n",
        "#manual link\n",
        "ee.Authenticate(force=True)"
      ],
      "metadata": {
        "id": "SRjFadsUD50b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "\n",
        "PROJECT_ID = 'ecowatch-ai-2026'\n",
        "\n",
        "try:\n",
        "    ee.Initialize(project=PROJECT_ID)\n",
        "    print(f\"Success! {PROJECT_ID} is now the active workspace for EcoWatch AI.\")\n",
        "except Exception as e:\n",
        "    print(f\"Initialization failed: {e}\")"
      ],
      "metadata": {
        "id": "C-2PjlGCEZ5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"AI Libraries and GEE Backend Ready.\")"
      ],
      "metadata": {
        "id": "UfUsxw_zHJnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_historical_loss(lat, lon, size_px=64):\n",
        "    #EcoWatch: 2000-2024 Timeline.\n",
        "\n",
        "    # Define the 960m x 960m area (30m pixels x 64px = 1920m total area)\n",
        "    region = ee.Geometry.Point([lon, lat]).buffer(size_px * 30 / 2).bounds()\n",
        "\n",
        "    # Load the definitive 2000-2024 Forest Change Dataset\n",
        "    gfc = ee.Image(\"UMD/hansen/global_forest_change_2024_v1_12\")\n",
        "\n",
        "    # 1. Background: Tree canopy cover in the year 2000 (0 to 100%)\n",
        "    base_2000 = gfc.select('treecover2000').clip(region)\n",
        "\n",
        "    # 2. Timeline: Pixels marked by the year of loss (1=2001 ... 24=2024)\n",
        "    loss_year = gfc.select('lossyear').clip(region)\n",
        "\n",
        "    # Bridge to AI: Convert to Numpy\n",
        "    # normalize treecover to [0, 1] for the model\n",
        "    base_np = geemap.ee_to_numpy(base_2000, region=region) / 100.0\n",
        "\n",
        "    # Label: Binary mask (any loss between 2001-2024 = 1, else 0)\n",
        "    loss_np = (geemap.ee_to_numpy(loss_year, region=region) > 0).astype(np.float32)\n",
        "\n",
        "    return base_np, loss_np"
      ],
      "metadata": {
        "id": "oP4_WrvYHKl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BUILD ATTENTION U-NET MODEL\n",
        "print(\"Building Attention U-Net for Forest Intelligence...\")\n",
        "\n",
        "class AttentionGate(layers.Layer):\n",
        "\n",
        "    #Attention Gate for U-Net helps the model focus on relevant vegetation health features\n",
        "\n",
        "    def __init__(self, filters, **kwargs):\n",
        "        super(AttentionGate, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Input shape: [(batch, h, w, c_g), (batch, h, w, c_x)]\n",
        "        self.W_g = layers.Conv2D(self.filters, 1, padding='same', use_bias=True)\n",
        "        self.W_x = layers.Conv2D(self.filters, 1, padding='same', use_bias=True)\n",
        "        self.psi = layers.Conv2D(1, 1, padding='same', use_bias=True)\n",
        "        self.relu = layers.ReLU()\n",
        "        self.sigmoid = layers.Activation('sigmoid')\n",
        "        super(AttentionGate, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        g, x = inputs  # g: gating signal, x: skip connection\n",
        "        g1 = self.W_g(g)\n",
        "        x1 = self.W_x(x)\n",
        "        psi = self.relu(g1 + x1)\n",
        "        psi = self.psi(psi)\n",
        "        psi = self.sigmoid(psi)\n",
        "        return x * psi\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(AttentionGate, self).get_config()\n",
        "        config.update({'filters': self.filters})\n",
        "        return config\n",
        "\n",
        "def conv_block(x, filters, kernel_size=3, name_prefix='conv'):\n",
        "   #Convolutional block with BatchNorm for satellite data stability\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same', activation='relu', name=f'{name_prefix}_conv1')(x)\n",
        "    x = layers.BatchNormalization(name=f'{name_prefix}_bn1')(x)\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same', activation='relu', name=f'{name_prefix}_conv2')(x)\n",
        "    x = layers.BatchNormalization(name=f'{name_prefix}_bn2')(x)\n",
        "    return x\n",
        "\n",
        "def build_attention_unet(input_shape=(64, 64, 1)):\n",
        "\n",
        "    #EcoWatch Attention U-Net optimized for single-channel NDVI inputs\n",
        "\n",
        "    inputs = layers.Input(input_shape, name='input')\n",
        "\n",
        "    #ENCODER\n",
        "    enc1 = conv_block(inputs, 32, name_prefix='enc1')\n",
        "    pool1 = layers.MaxPooling2D(2, name='pool1')(enc1)\n",
        "\n",
        "    enc2 = conv_block(pool1, 64, name_prefix='enc2')\n",
        "    pool2 = layers.MaxPooling2D(2, name='pool2')(enc2)\n",
        "\n",
        "    enc3 = conv_block(pool2, 128, name_prefix='enc3')\n",
        "    pool3 = layers.MaxPooling2D(2, name='pool3')(enc3)\n",
        "\n",
        "    enc4 = conv_block(pool3, 256, name_prefix='enc4')\n",
        "    pool4 = layers.MaxPooling2D(2, name='pool4')(enc4)\n",
        "\n",
        "    #BOTTLENECK\n",
        "    bottleneck = conv_block(pool4, 512, name_prefix='bottleneck')\n",
        "\n",
        "    #DECODER WITH ATTENTION\n",
        "    up1 = layers.UpSampling2D(2, name='up1')(bottleneck)\n",
        "    up1 = layers.Conv2D(256, 2, padding='same', activation='relu', name='up1_conv')(up1)\n",
        "    att1 = AttentionGate(256, name='att_gate1')([up1, enc4])\n",
        "    merge1 = layers.Concatenate(name='merge1')([up1, att1])\n",
        "    dec1 = conv_block(merge1, 256, name_prefix='dec1')\n",
        "\n",
        "    up2 = layers.UpSampling2D(2, name='up2')(dec1)\n",
        "    up2 = layers.Conv2D(128, 2, padding='same', activation='relu', name='up2_conv')(up2)\n",
        "    att2 = AttentionGate(128, name='att_gate2')([up2, enc3])\n",
        "    merge2 = layers.Concatenate(name='merge2')([up2, att2])\n",
        "    dec2 = conv_block(merge2, 128, name_prefix='dec2')\n",
        "\n",
        "    up3 = layers.UpSampling2D(2, name='up3')(dec2)\n",
        "    up3 = layers.Conv2D(64, 2, padding='same', activation='relu', name='up3_conv')(up3)\n",
        "    att3 = AttentionGate(64, name='att_gate3')([up3, enc2])\n",
        "    merge3 = layers.Concatenate(name='merge3')([up3, att3])\n",
        "    dec3 = conv_block(merge3, 64, name_prefix='dec3')\n",
        "\n",
        "    up4 = layers.UpSampling2D(2, name='up4')(dec3)\n",
        "    up4 = layers.Conv2D(32, 2, padding='same', activation='relu', name='up4_conv')(up4)\n",
        "    att4 = AttentionGate(32, name='att_gate4')([up4, enc1])\n",
        "    merge4 = layers.Concatenate(name='merge4')([up4, att4])\n",
        "    dec4 = conv_block(merge4, 32, name_prefix='dec4')\n",
        "\n",
        "    #OUTPUT: Binary Forest Loss Prediction\n",
        "    outputs = layers.Conv2D(1, 1, activation='sigmoid', dtype='float32', name='output')(dec4)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs, name='EcoWatch_AttentionUNet')\n",
        "    return model\n",
        "\n",
        "#COMPILE MODEL\n",
        "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def combined_loss(y_true, y_pred):\n",
        "    focal = tf.keras.losses.BinaryFocalCrossentropy(alpha=0.25, gamma=2.0)(y_true, y_pred)\n",
        "    dice = 1 - dice_coefficient(y_true, y_pred)\n",
        "    return 0.5 * focal + 0.5 * dice\n",
        "\n",
        "model = build_attention_unet()\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=combined_loss,\n",
        "    metrics=['accuracy', tf.keras.metrics.Recall(name='recall'), dice_coefficient]\n",
        ")\n",
        "\n",
        "print(\"Attention U-Net Model ready for EcoWatch training loop.\")"
      ],
      "metadata": {
        "id": "slYT7CtJHcD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize\n",
        "\n",
        "# Target hotspots for high-impact signatures\n",
        "hotspots = [\n",
        "    [22.91, 92.95], [23.10, 92.80], [22.80, 93.10], # Mizoram\n",
        "    [25.55, 93.68], [25.70, 93.80], [25.40, 93.50], # Nagaland\n",
        "    [-11.40, -58.57], [-11.50, -58.70], [-11.30, -58.40], # Amazon\n",
        "    [-0.50, 20.00], [-0.60, 20.10], [-0.40, 19.90]  # Congo\n",
        "]\n",
        "\n",
        "X_train_list, y_train_list = [], []\n",
        "\n",
        "print(\"Harvesting & Standardizing Expanded Training Set...\")\n",
        "\n",
        "for lat, lon in hotspots:\n",
        "    try:\n",
        "        # Pull 24-year historical data\n",
        "        img, loss = fetch_historical_loss(lat, lon)\n",
        "\n",
        "        # Standardize shape to exactly 64x64x1\n",
        "        img_std = resize(img, (64, 64, 1), preserve_range=True)\n",
        "        loss_std = resize(loss, (64, 64, 1), preserve_range=True)\n",
        "\n",
        "        # Augmentation: Add 4 rotations of each patch\n",
        "        for r in [0, 1, 2, 3]:\n",
        "            X_train_list.append(np.rot90(img_std, r))\n",
        "            y_train_list.append(np.rot90(loss_std, r))\n",
        "\n",
        "    except Exception as e:\n",
        "        continue\n",
        "\n",
        "# Convert to final Numpy arrays\n",
        "X_train = np.array(X_train_list)\n",
        "y_train = np.array(y_train_list)\n",
        "\n",
        "print(f\"Final Training Set: {X_train.shape[0]} patches ready!\")"
      ],
      "metadata": {
        "id": "qeGWO3tEaV_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Launching Attention U-Net Training...\")\n",
        "\n",
        "# Training for 50 epochs to allow convergence\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=4,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nTraining Complete! The model is now tuned for global biomes.\")"
      ],
      "metadata": {
        "id": "Y_Uef56maXhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generating 24-Year Visual Validation Report...\\n\")\n",
        "\n",
        "target_names = [\"Mizoram, India\", \"Nagaland, India\", \"Amazon, Brazil\", \"Congo Basin, DRC\"]\n",
        "demo_locations = [[22.91, 92.95], [25.55, 93.68], [-11.40, -58.57], [-0.50, 20.00]]\n",
        "\n",
        "fig, axes = plt.subplots(4, 3, figsize=(18, 20))\n",
        "\n",
        "for i, loc in enumerate(demo_locations):\n",
        "    # Retrieve and standardize input for visualization\n",
        "    img, loss = fetch_historical_loss(loc[0], loc[1])\n",
        "    img = resize(img, (64, 64, 1), preserve_range=True)\n",
        "\n",
        "    # Run prediction\n",
        "    pred = model.predict(np.expand_dims(img, axis=0), verbose=0)[0]\n",
        "\n",
        "    # 1. Forest Canopy in 2000\n",
        "    axes[i, 0].imshow(img.squeeze(), cmap='Greens')\n",
        "    axes[i, 0].set_title(f\"{target_names[i]}\\nForest Canopy (2000)\", fontweight='bold')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # 2. Actual Historical Loss (2000-2024)\n",
        "    axes[i, 1].imshow(loss.squeeze(), cmap='Reds')\n",
        "    axes[i, 1].set_title(\"Actual Loss (2000-2024)\", fontweight='bold')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "    # 3. AI Prediction (Thresholded at 0.5 for sharpness)\n",
        "    axes[i, 2].imshow(pred.squeeze() > 0.5, cmap='OrRd')\n",
        "    axes[i, 2].set_title(\"EcoWatch AI Prediction\", fontweight='bold')\n",
        "    axes[i, 2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KvmHDssicZgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generating EcoWatch AI Final Impact Report (2000-2024)...\")\n",
        "\n",
        "# Calculate statistics for each of your 4 official targets\n",
        "for i in range(len(X_final)):\n",
        "    # Calculate total forest pixels in 2000 (Baseline)\n",
        "    # We use a threshold of 0.3 to define 'forested' areas in the year 2000\n",
        "    forest_2000_pixels = np.sum(X_final[i] > 0.3)\n",
        "\n",
        "    # Calculate pixels lost by 2024\n",
        "    loss_pixels = np.sum(y_final[i] > 0)\n",
        "\n",
        "    # Calculate AI's predicted loss pixels\n",
        "    pred = model.predict(X_final[i:i+1], verbose=0)[0]\n",
        "    pred_loss_pixels = np.sum(pred > 0.5)\n",
        "\n",
        "    # Percentage calculation\n",
        "    actual_loss_pct = (loss_pixels / forest_2000_pixels) * 100 if forest_2000_pixels > 0 else 0\n",
        "    ai_confidence = (1 - abs(pred_loss_pixels - loss_pixels) / loss_pixels) * 100 if loss_pixels > 0 else 100\n",
        "\n",
        "    print(f\"REGION: {target_names[i]}\")\n",
        "    print(f\"• Baseline Forest Density (2000): {np.mean(X_final[i])*100:.1f}%\")\n",
        "    print(f\"• Actual Forest Loss (2000-2024): {actual_loss_pct:.1f}% of canopy\")\n",
        "    print(f\"• AI Prediction Accuracy:        {ai_confidence:.1f}%\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Final Summary\n",
        "eval_metrics = model.evaluate(X_train, y_train, verbose=0)\n",
        "print(f\"\\nFINAL MODEL STANDINGS:\")\n",
        "print(f\"• Global Accuracy: {eval_metrics[1]*100:.2f}%\")\n",
        "print(f\"• Dice Coefficient: {eval_metrics[3]:.4f}\")\n",
        "print(f\"• Recall Rate:      {eval_metrics[2]*100:.2f}%\")"
      ],
      "metadata": {
        "id": "qsnDmpidcaEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "drive_folder = '/content/drive/MyDrive/EcoWatch_Hacksagon'\n",
        "\n",
        "if not os.path.exists(drive_folder):\n",
        "    os.makedirs(drive_folder)\n",
        "    print(f\"Created new directory: {drive_folder}\")\n",
        "\n",
        "model_filename = 'ecowatch_v1_final.keras'\n",
        "save_path = os.path.join(drive_folder, model_filename)\n",
        "\n",
        "model.save(save_path)\n",
        "\n",
        "print(f\"Model saved at {save_path}\")"
      ],
      "metadata": {
        "id": "hs9NLtRBq6cW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}